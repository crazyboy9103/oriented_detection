{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "train_file = \"/datasets/mvtec/mvtec_screws_train.json\"\n",
    "val_file = \"/datasets/mvtec/mvtec_screws_val.json\"\n",
    "test_file = \"/datasets/mvtec/mvtec_screws_test.json\"\n",
    "category_names = {7:'nut', 3:'wood_screw', 2:'lag_wood_screw', 8:'bolt',\n",
    "                  6:'black_oxide_screw', 5:'shiny_screw', 4:'short_wood_screw',\n",
    "                  1:'long_lag_screw', 9:'large_nut', 11:'nut2', 10:'nut1',\n",
    "                  12:'machine_screw', 13:'short_machine_screw' }\n",
    "\n",
    "import numpy as np\n",
    "def xywha2xy4(xywha):  # a represents the angle(rad), clockwise, a=0 along the X axis\n",
    "    x, y, w, h, a = xywha\n",
    "    corner = np.array([[-w / 2, -h / 2], [w / 2, -h / 2], [w / 2, h / 2], [-w / 2, h / 2]])\n",
    "    transform = np.array([[np.cos(a), -np.sin(a)], [np.sin(a), np.cos(a)]])\n",
    "    return (transform.dot(corner.T).T + [x, y]).tolist()\n",
    "\n",
    "def get_dota_fmt(file):\n",
    "    label_file = json.load(open(file, \"r\"))\n",
    "    \n",
    "    image_name_lines = {}\n",
    "    image_id_names = {}\n",
    "    for img in label_file[\"images\"]:\n",
    "        image_name_lines[img[\"file_name\"]] = []\n",
    "        image_id_names[img[\"id\"]] = img[\"file_name\"]\n",
    "        \n",
    "    for ant in label_file[\"annotations\"]:\n",
    "        category_id = ant[\"category_id\"]\n",
    "        image_id = ant[\"image_id\"]\n",
    "        ant_id = ant[\"id\"]\n",
    "        \n",
    "        # cx, cy가 아닌 cy, cx로 레이블링 되어있음\n",
    "        cy, cx, w, h, a = ant[\"bbox\"]\n",
    "        \n",
    "        # angle은 [-pi, pi] 라고 했는데, 해당 범위를 넘어가는 데이터가 존재하므로 \n",
    "        # [-pi, pi] 범위로 재조정\n",
    "        if a != 0:\n",
    "            a = (a / abs(a))  * (abs(a) % np.pi)\n",
    "        \n",
    "        # xywha2xy4 함수를 사용하기 위해서 [0, 2pi] 범위로 조정 (clockwise)\n",
    "        if a < 0:\n",
    "            a *= -1\n",
    "        elif a > 0:\n",
    "            a = 2*np.pi-a\n",
    "\n",
    "        xy4 = xywha2xy4((cx, cy, w, h, a))\n",
    "        \n",
    "        label = category_names[category_id]\n",
    "        \n",
    "        # DOTA 포맷 line\n",
    "        line = []\n",
    "        for xy in xy4:\n",
    "            line.extend(map(int, xy))\n",
    "        \n",
    "        line.append(label)\n",
    "        # difficulty\n",
    "        line.append(0)        \n",
    "        line = \" \".join(map(str, line))\n",
    "        image_name_lines[image_id_names[image_id]].append(line)\n",
    "    return image_name_lines\n",
    "\n",
    "train_image_name_lines = get_dota_fmt(train_file)\n",
    "val_image_name_lines = get_dota_fmt(val_file)\n",
    "test_image_name_lines = get_dota_fmt(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_labels(image_name_lines):\n",
    "    os.makedirs(\"/datasets/mvtec/annfiles\", exist_ok=True)\n",
    "    for image_name, lines in image_name_lines.items():\n",
    "        txt_path = os.path.join(\"/datasets/mvtec/annfiles\", image_name.rstrip(\".png\")+\".txt\")\n",
    "        with open(txt_path, \"w\") as f:\n",
    "            for line in lines:\n",
    "                f.writelines(line + \"\\n\")\n",
    "write_to_labels(train_image_name_lines)\n",
    "write_to_labels(val_image_name_lines)\n",
    "write_to_labels(test_image_name_lines)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import shutil\n",
    "\n",
    "anns_path = \"/datasets/mvtec/annfiles\"\n",
    "imgs_path = \"/datasets/mvtec/images\"\n",
    "trainval_path = \"/datasets/mvtec/trainval\"\n",
    "test_path = \"/datasets/mvtec/test\"\n",
    "import os\n",
    "trainval_imgs_path = os.path.join(trainval_path, \"images\")\n",
    "trainval_anns_path = os.path.join(trainval_path, \"annfiles\")\n",
    "test_imgs_path = os.path.join(test_path, \"images\")\n",
    "test_anns_path = os.path.join(test_path, \"annfiles\")\n",
    "\n",
    "os.makedirs(trainval_imgs_path, exist_ok=True)\n",
    "os.makedirs(trainval_anns_path, exist_ok=True)\n",
    "os.makedirs(test_imgs_path, exist_ok=True)\n",
    "os.makedirs(test_anns_path, exist_ok=True)\n",
    "\n",
    "txtfiles = glob.glob(\"/datasets/mvtec/annfiles/*.txt\")\n",
    "import random\n",
    "random.shuffle(txtfiles)\n",
    "imgfiles = [txtfile.replace(\"annfiles\", \"images\").replace(\".txt\", \".png\") for txtfile in txtfiles]\n",
    "\n",
    "n = len(txtfiles)\n",
    "n_train = int(n*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txtfiles = txtfiles[:n_train]\n",
    "train_imgfiles = imgfiles[:n_train]\n",
    "\n",
    "for train_txtfile, train_imgfile in zip(train_txtfiles, train_imgfiles):\n",
    "    txtfilename = train_txtfile.split(\"/\")[-1]\n",
    "    imgfilename = train_imgfile.split(\"/\")[-1]\n",
    "    shutil.copy(train_txtfile, os.path.join(trainval_anns_path, txtfilename))\n",
    "    shutil.copy(train_imgfile, os.path.join(trainval_imgs_path, imgfilename))\n",
    "    \n",
    "test_txtfiles = txtfiles[n_train:]\n",
    "test_imgfiles = imgfiles[n_train:]\n",
    "\n",
    "for test_txtfile, test_imgfile in zip(test_txtfiles, test_imgfiles):\n",
    "    txtfilename = test_txtfile.split(\"/\")[-1]\n",
    "    imgfilename = test_imgfile.split(\"/\")[-1]\n",
    "    shutil.copy(test_txtfile, os.path.join(test_anns_path, txtfilename))\n",
    "    shutil.copy(test_imgfile, os.path.join(test_imgs_path, imgfilename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a=torch.load(\"../datasets/mvtec_balanced.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
